{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "cancer_data = pd.read_csv(\"new_data.csv\")\n",
    "print \"Data read successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries: 569\n",
      "Number of features: 30\n",
      "Number of malignant entries: 212\n",
      "Number of benign entries: 357\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate number of students\n",
    "n_entries = cancer_data.shape[0]\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "n_features = cancer_data.shape[1]-1\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "n_malignant = cancer_data[cancer_data['diagnosis']== 1].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_benign = cancer_data[cancer_data['diagnosis'] == 0].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print \"Total number of entries: {}\".format(n_entries)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Number of malignant entries: {}\".format(n_malignant)\n",
    "print \"Number of benign entries: {}\".format(n_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
      "\n",
      "Target column: diagnosis\n",
      "\n",
      "Feature values:\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
      "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
      "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
      "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
      "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          0.792037        0.703140             0.731113       0.686364   \n",
      "1          0.181768        0.203608             0.348757       0.379798   \n",
      "2          0.431017        0.462512             0.635686       0.509596   \n",
      "3          0.811361        0.565604             0.522863       0.776263   \n",
      "4          0.347893        0.463918             0.518390       0.378283   \n",
      "\n",
      "   fractal_dimension_mean           ...             radius_worst  \\\n",
      "0                0.605518           ...                 0.620776   \n",
      "1                0.141323           ...                 0.606901   \n",
      "2                0.211247           ...                 0.556386   \n",
      "3                1.000000           ...                 0.248310   \n",
      "4                0.186816           ...                 0.519744   \n",
      "\n",
      "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0       0.141525         0.668310    0.450698          0.601136   \n",
      "1       0.303571         0.539818    0.435214          0.347553   \n",
      "2       0.360075         0.508442    0.374508          0.483590   \n",
      "3       0.385928         0.241347    0.094008          0.915472   \n",
      "4       0.123934         0.506948    0.341575          0.437364   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0           0.619292         0.568610              0.912027        0.598462   \n",
      "1           0.154563         0.192971              0.639175        0.233590   \n",
      "2           0.385375         0.359744              0.835052        0.403706   \n",
      "3           0.814012         0.548642              0.884880        1.000000   \n",
      "4           0.172415         0.319489              0.558419        0.157500   \n",
      "\n",
      "   fractal_dimension_worst  \n",
      "0                 0.418864  \n",
      "1                 0.222878  \n",
      "2                 0.213433  \n",
      "3                 0.773711  \n",
      "4                 0.142595  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(cancer_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'diagnosis'\n",
    "target_col = cancer_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = cancer_data[feature_cols]\n",
    "y_all = cancer_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 479 samples.\n",
      "Testing set has 90 samples.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO: Set the number of training points\n",
    "num_train = 479\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=90, random_state=42)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print 'Trained model in {:.4f} seconds'.format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {:.4f}.\\n\\n\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(num_train, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "        \n",
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SklearnHelper using a training set size of 479. . .\n",
      "Trained model in 1.5072 seconds\n",
      "Made predictions in 0.3310 seconds.\n",
      "F1 score for training set: 0.9915.\n",
      "Made predictions in 0.2020 seconds.\n",
      "F1 score for test set: 0.9394.\n",
      "\n",
      "\n",
      "Training a SklearnHelper using a training set size of 479. . .\n",
      "Trained model in 1.4521 seconds\n",
      "Made predictions in 0.3465 seconds.\n",
      "F1 score for training set: 0.9886.\n",
      "Made predictions in 0.2047 seconds.\n",
      "F1 score for test set: 0.9394.\n",
      "\n",
      "\n",
      "Training a SklearnHelper using a training set size of 479. . .\n",
      "Trained model in 1.8923 seconds\n",
      "Made predictions in 0.0733 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0415 seconds.\n",
      "F1 score for test set: 0.9552.\n",
      "\n",
      "\n",
      "Training a SklearnHelper using a training set size of 479. . .\n",
      "Trained model in 0.3265 seconds\n",
      "Made predictions in 0.0021 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for test set: 0.9394.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "\n",
    "train_predict(rf, X_train, y_train, X_test, y_test)\n",
    "train_predict(et, X_train, y_train, X_test, y_test)\n",
    "train_predict(ada, X_train, y_train, X_test, y_test)\n",
    "train_predict(gb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_feature = rf.fit(X_train, y_train).feature_importances_\n",
    "et_feature = et.fit(X_train, y_train).feature_importances_\n",
    "ada_feature = ada.fit(X_train, y_train).feature_importances_\n",
    "gb_feature = gb.fit(X_train, y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03627394  0.01456477  0.04996821  0.04098817  0.00548078  0.01384331\n",
      "   0.05571153  0.11333541  0.00259449  0.0038415   0.01633188  0.00390766\n",
      "   0.01152841  0.03085779  0.00382046  0.00366677  0.00546514  0.00432612\n",
      "   0.00328915  0.00445075  0.11737634  0.01931315  0.1226758   0.11380129\n",
      "   0.00928052  0.01397712  0.03967421  0.11967989  0.01365017  0.00632528]\n",
      " [ 0.06002688  0.01837291  0.0692622   0.05826016  0.0075222   0.02312954\n",
      "   0.0580876   0.08951156  0.00625699  0.00514714  0.0139623   0.00307909\n",
      "   0.01468696  0.02544779  0.00261136  0.00540793  0.0056671   0.00826967\n",
      "   0.00240206  0.00362764  0.09070681  0.02178458  0.09151255  0.07963792\n",
      "   0.01618595  0.02747416  0.04093342  0.12885889  0.01529869  0.00686796]\n",
      " [ 0.          0.082       0.004       0.03        0.046       0.066       0.03\n",
      "   0.05        0.034       0.01        0.03        0.01        0.008       0.042\n",
      "   0.028       0.076       0.004       0.026       0.008       0.036       0.01\n",
      "   0.064       0.028       0.046       0.052       0.01        0.058       0.048\n",
      "   0.05        0.014     ]\n",
      " [ 0.00096217  0.00486666  0.00021957  0.00043026  0.00088631  0.00256269\n",
      "   0.00107464  0.04483419  0.00034885  0.00015724  0.00692784  0.0006387\n",
      "   0.00319685  0.00676764  0.00165952  0.00440606  0.00049392  0.0011524\n",
      "   0.00197618  0.00069849  0.01781051  0.01025071  0.00743798  0.00622692\n",
      "   0.00103375  0.00133447  0.03155486  0.01880709  0.00078121  0.00050234]]\n",
      "\n",
      "\n",
      "AVERAGE\n",
      "\n",
      "\n",
      "[ 0.02431575  0.02995109  0.0308625   0.03241965  0.01497232  0.02638389\n",
      "  0.03621844  0.07442029  0.01080008  0.00478647  0.0168055   0.00440636\n",
      "  0.00935305  0.02626831  0.00902284  0.02237019  0.00390654  0.00993705\n",
      "  0.00391685  0.01119422  0.05897341  0.02883711  0.06240658  0.06141653\n",
      "  0.01962505  0.01319644  0.04254062  0.07883647  0.01993252  0.00692389]\n"
     ]
    }
   ],
   "source": [
    "#averaging the feature_importances obtained from the different classifiers\n",
    "\n",
    "a = np.array([rf_feature, et_feature, ada_feature, gb_feature])\n",
    "print a\n",
    "avg_array = np.mean(a, axis=0)\n",
    "print \"\\n\\nAVERAGE\\n\\n\"\n",
    "print avg_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#print type(feature_cols)\n",
    "#print feature_cols\n",
    "avg_list = list(avg_array)\n",
    "#print type(avg_list)\n",
    "#print avg_list\n",
    "\n",
    "#sorting both lists in sync with each other (ascending order of average feature_importance)\n",
    "list1, list2 = (list(t) for t in zip(*sorted(zip(avg_list, feature_cols))))\n",
    "\n",
    "list1.reverse()\n",
    "list2.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copying the two columns into an excel sheet\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Color, PatternFill, Font, Border\n",
    "from openpyxl.styles import colors\n",
    "from openpyxl.cell import Cell\n",
    "import xlrd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import worksheet\n",
    "\n",
    "wb_write = Workbook()\n",
    "ws_write = wb_write.get_active_sheet()\n",
    "\n",
    "for i in range(0, len(list1)):\n",
    "    write_cell = ws_write.cell(row=i+1, column=1)\n",
    "    write_cell.value = list2[i];\n",
    "\n",
    "for i in range(0, len(list1)):\n",
    "    write_cell = ws_write.cell(row=i+1, column=2)\n",
    "    write_cell.value = list1[i];\n",
    "\n",
    "wb_write.save('pred_power.xlsx')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
